{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CMPE256_RecSys_I_Problems.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KunjParikh/cmpe256/blob/master/HWs/CMPE256_RecSys_I_Problems.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OTjw-ALdYR0r",
        "colab_type": "text"
      },
      "source": [
        "## (40%) Collaboraitve Filtering Movie Recommendation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "loulTTsCExlX",
        "colab_type": "code",
        "outputId": "83f8d697-4fd6-4df6-a4cc-9f58ced6dfcd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 467
        }
      },
      "source": [
        "#Need this cell only for google colab envt.\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "!ln -s gdrive/'My Drive'/SJSU/'large scale analytics'/HWs gdata\n",
        "!pip install requests\n",
        "!pip install python-firebase"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (2.21.0)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests) (2019.3.9)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests) (2.8)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests) (1.24.3)\n",
            "Collecting python-firebase\n",
            "  Downloading https://files.pythonhosted.org/packages/32/e6/88b799753e64aeb0f24040b98c94012994cf9517c889dee4f8a49ac89400/python-firebase-1.2.tar.gz\n",
            "Requirement already satisfied: requests>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from python-firebase) (2.21.0)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=1.1.0->python-firebase) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=1.1.0->python-firebase) (2019.3.9)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=1.1.0->python-firebase) (3.0.4)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=1.1.0->python-firebase) (2.8)\n",
            "Building wheels for collected packages: python-firebase\n",
            "  Building wheel for python-firebase (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Stored in directory: /root/.cache/pip/wheels/ba/40/ca/e41a25d7abb787092e837cb0f91f33b04b1a8fd9d17c2d33a6\n",
            "Successfully built python-firebase\n",
            "Installing collected packages: python-firebase\n",
            "Successfully installed python-firebase-1.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A0lx7f-mJ8X2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Modules used.\n",
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zRQBN2w3YR00",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#A Dictionary of movie critics and their ratings of a small set of movies\n",
        "critics={\n",
        "  'Lisa Rose': {\n",
        "    'Lady in the Water': 2.5, \n",
        "    'Snakes on a Plane': 3.5,\n",
        "    'Just My Luck': 3.0, \n",
        "    'Superman Returns': 3.5, \n",
        "    'You, Me and Dupree': 2.5,\n",
        "    'The Night Listener': 3.0\n",
        "  },\n",
        "  'Gene Seymour': {\n",
        "    'Lady in the Water': 3.0, \n",
        "    'Snakes on a Plane': 3.5,\n",
        "    'Just My Luck': 1.5, \n",
        "    'Superman Returns': 5.0, \n",
        "    'The Night Listener': 3.0,\n",
        "    'You, Me and Dupree': 3.5\n",
        "  },\n",
        "  'Michael Phillips': {\n",
        "    'Lady in the Water': 2.5, \n",
        "    'Snakes on a Plane': 3.0,\n",
        "    'Superman Returns': 3.5, \n",
        "    'The Night Listener': 4.0\n",
        "  },\n",
        "  'Claudia Puig': {\n",
        "    'Snakes on a Plane': 3.5, \n",
        "    'Just My Luck': 3.0,\n",
        "    'The Night Listener': 4.5, \n",
        "    'Superman Returns': 4.0,\n",
        "    'You, Me and Dupree': 2.5\n",
        "  },\n",
        "  'Mick LaSalle': {\n",
        "    'Lady in the Water': 3.0, \n",
        "    'Snakes on a Plane': 4.0,\n",
        "    'Just My Luck': 2.0, \n",
        "    'Superman Returns': 3.0, \n",
        "    'The Night Listener': 3.0,\n",
        "    'You, Me and Dupree': 2.0\n",
        "  },\n",
        "  'Jack Matthews': {\n",
        "    'Lady in the Water': 3.0, \n",
        "    'Snakes on a Plane': 4.0,\n",
        "    'The Night Listener': 3.0, \n",
        "    'Superman Returns': 5.0, \n",
        "    'You, Me and Dupree': 3.5\n",
        "  },\n",
        "  'Toby': {\n",
        "    'Snakes on a Plane':4.5,\n",
        "    'You, Me and Dupree':1.0,\n",
        "    'Superman Returns':4.0\n",
        "  }\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "brb9pqpYYR1J",
        "colab_type": "text"
      },
      "source": [
        "### Suppose we are given a data set above of each customrs' rating to each movie with sacle 0-5. Stored as python dictinary format. Can you write a function with inputs of rating data and two persons, return their similarity measured by Pearson correlation. You may define and implment other similarity measure also. (10%). "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Btyuo1DYR1M",
        "colab_type": "text"
      },
      "source": [
        "#### Solutions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_m_1wKa0esMO",
        "colab_type": "text"
      },
      "source": [
        "Pearson coefficient similarity : \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sH8w1mq1tQ8e",
        "colab_type": "code",
        "outputId": "6a5aea40-c63f-460f-da55-c3cfc46c837a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        }
      },
      "source": [
        "def processDict(dict):\n",
        "  df = pd.DataFrame.from_dict(dict)\n",
        "  #critics_df = critics_df.fillna(0.0) #Don't do this!!!! NaN is handled correclty for mean.\n",
        "  df = df.transpose()\n",
        "  return df\n",
        "\n",
        "critics_df = processDict(critics)\n",
        "critics_df"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Just My Luck</th>\n",
              "      <th>Lady in the Water</th>\n",
              "      <th>Snakes on a Plane</th>\n",
              "      <th>Superman Returns</th>\n",
              "      <th>The Night Listener</th>\n",
              "      <th>You, Me and Dupree</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Lisa Rose</th>\n",
              "      <td>3.0</td>\n",
              "      <td>2.5</td>\n",
              "      <td>3.5</td>\n",
              "      <td>3.5</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Gene Seymour</th>\n",
              "      <td>1.5</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.5</td>\n",
              "      <td>5.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Michael Phillips</th>\n",
              "      <td>NaN</td>\n",
              "      <td>2.5</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.5</td>\n",
              "      <td>4.0</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Claudia Puig</th>\n",
              "      <td>3.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>3.5</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.5</td>\n",
              "      <td>2.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Mick LaSalle</th>\n",
              "      <td>2.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Jack Matthews</th>\n",
              "      <td>NaN</td>\n",
              "      <td>3.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Toby</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>4.5</td>\n",
              "      <td>4.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                  Just My Luck  ...  You, Me and Dupree\n",
              "Lisa Rose                  3.0  ...                 2.5\n",
              "Gene Seymour               1.5  ...                 3.5\n",
              "Michael Phillips           NaN  ...                 NaN\n",
              "Claudia Puig               3.0  ...                 2.5\n",
              "Mick LaSalle               2.0  ...                 2.0\n",
              "Jack Matthews              NaN  ...                 3.5\n",
              "Toby                       NaN  ...                 1.0\n",
              "\n",
              "[7 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L2ywgDDpYR1Q",
        "colab_type": "code",
        "outputId": "08027606-6840-4d32-d110-05981cbb0146",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "source": [
        "#Substract mean from each row.\n",
        "def similarity(df, p1, p2):\n",
        "  df = df.sub(df.mean(axis=1), axis=0) #Remove mean rating for similarity.\n",
        "  #After removing mean we can replace NaN with 0.\n",
        "  df = df.fillna(0.0)\n",
        "  p1 = df.loc[p1].values\n",
        "  p2 = df.loc[p2].values\n",
        "  numerator = np.dot(p1, p2)\n",
        "  denominator = np.sqrt(np.dot(p1, p1) * np.dot(p2, p2))\n",
        "  return numerator / denominator\n",
        "  \n",
        "\n",
        "similarity(critics_df, 'Lisa Rose',  'Toby')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8093446482740976"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "08OcU1kVYR1a",
        "colab_type": "text"
      },
      "source": [
        "### Given a person, say A, could you write a function to return top n persons most similar to A (exclude A) (5%)? \n",
        "### Same dataset as above."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eWdDLgFIYR1e",
        "colab_type": "text"
      },
      "source": [
        "#### Solutions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R_d2a4SOYR1h",
        "colab_type": "code",
        "outputId": "4c0b944b-3756-436c-d3ef-7b4c098ccd80",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "source": [
        "#Similarity matrix\n",
        "def similarityMatrix(df):\n",
        "  sim_mat = pd.DataFrame(index=df.index.values, columns=df.index.values)\n",
        "  for p1 in sim_mat.index.values:\n",
        "    for p2 in sim_mat.columns.values:\n",
        "      sim_mat[p1][p2] = similarity(df, p1, p2)\n",
        "  return sim_mat\n",
        "\n",
        "def mostSimilar(df, person, num):\n",
        "  sim_mat = similarityMatrix(df)\n",
        "  #Series and sorted descending\n",
        "  sims = sim_mat[person].sort_values(ascending = False)\n",
        "  #Get Series labels and return ndarray\n",
        "  return sims.index[1:num+1].values\n",
        "\n",
        "mostSimilar(critics_df, 'Lisa Rose', 2)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['Toby', 'Jack Matthews'], dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 140
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uGF2jXtaYR1u",
        "colab_type": "text"
      },
      "source": [
        "### Given a person, say A, could you write a function to recommend those unseen movies? (10%)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Co9ADf9JYR1y",
        "colab_type": "text"
      },
      "source": [
        "#### Solutions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gCKn1yNYYR13",
        "colab_type": "code",
        "outputId": "cb05d5f3-b605-4d57-8c68-e9b0f262d054",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        }
      },
      "source": [
        "#Use Prediction formula from class. pred = ra' + sum(sim*(rpb - rb'))/sum(sim)\n",
        "#We already have means removed from rating.. so its just ra' + sum(sim*rb)/sum(sim)\n",
        "def prediction(df, person, movie):\n",
        "  simMat = similarityMatrix(df)\n",
        "  personAverage = df.mean(axis=1).loc[person]\n",
        "  similarities= simMat.loc[person].values\n",
        "  #Replace NaN with 0.0 to ignore them in num. \n",
        "  #To ignore them in deno create flag.\n",
        "  ratings = df[:][movie].fillna(0.0).values\n",
        "  flag = np.array([1 if x>0 else 0 for x in ratings])\n",
        "  numerator = np.dot(similarities, ratings)\n",
        "  denominator = np.dot(similarities, flag)\n",
        "  return personAverage + (numerator / denominator)\n",
        "\n",
        "#Return cmpNum movies\n",
        "def suggest(df, person, cmpNum=1):\n",
        "  \n",
        "  notWatchedMovies = df.loc[person] #Next Filter on Series\n",
        "  notWatchedMovies = notWatchedMovies[notWatchedMovies.isnull()].index.values\n",
        "  \n",
        "  pred_rating = pd.Series(index = notWatchedMovies)\n",
        "  for movie in notWatchedMovies:\n",
        "    pred_rating[movie] = prediction(df, person, movie)\n",
        "    \n",
        "  watchThese = pred_rating.sort_values(ascending = False).index.values\n",
        "  print(\"Watch these movies, first one first: {}\".format(watchThese))\n",
        "  return watchThese\n",
        "\n",
        "#prediction(critics_df, 'Toby', 'Just My Luck')\n",
        "suggest(critics_df, 'Toby')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Watch these movies, first one first: ['The Night Listener' 'Lady in the Water' 'Just My Luck']\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['The Night Listener', 'Lady in the Water', 'Just My Luck'],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 120
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EhDdcyNRYR2A",
        "colab_type": "text"
      },
      "source": [
        "### Let's using another approach, can you write a function to return top n most similair movies for a given movie? (5%) "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_0_SyNccYR2E",
        "colab_type": "text"
      },
      "source": [
        "#### Solutions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RgTI2QxVYR2L",
        "colab_type": "code",
        "outputId": "676c1083-571c-4bfb-d74c-69a19da1a3ea",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 237
        }
      },
      "source": [
        "movie_df = critics_df.transpose()\n",
        "movie_df"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Lisa Rose</th>\n",
              "      <th>Gene Seymour</th>\n",
              "      <th>Michael Phillips</th>\n",
              "      <th>Claudia Puig</th>\n",
              "      <th>Mick LaSalle</th>\n",
              "      <th>Jack Matthews</th>\n",
              "      <th>Toby</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Just My Luck</th>\n",
              "      <td>3.0</td>\n",
              "      <td>1.5</td>\n",
              "      <td>NaN</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Lady in the Water</th>\n",
              "      <td>2.5</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2.5</td>\n",
              "      <td>NaN</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Snakes on a Plane</th>\n",
              "      <td>3.5</td>\n",
              "      <td>3.5</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.5</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Superman Returns</th>\n",
              "      <td>3.5</td>\n",
              "      <td>5.0</td>\n",
              "      <td>3.5</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>4.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>The Night Listener</th>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.5</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>You, Me and Dupree</th>\n",
              "      <td>2.5</td>\n",
              "      <td>3.5</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2.5</td>\n",
              "      <td>2.0</td>\n",
              "      <td>3.5</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                    Lisa Rose  Gene Seymour  ...  Jack Matthews  Toby\n",
              "Just My Luck              3.0           1.5  ...            NaN   NaN\n",
              "Lady in the Water         2.5           3.0  ...            3.0   NaN\n",
              "Snakes on a Plane         3.5           3.5  ...            4.0   4.5\n",
              "Superman Returns          3.5           5.0  ...            5.0   4.0\n",
              "The Night Listener        3.0           3.0  ...            3.0   NaN\n",
              "You, Me and Dupree        2.5           3.5  ...            3.5   1.0\n",
              "\n",
              "[6 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 121
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QDFQ3qD9oI0d",
        "colab_type": "code",
        "outputId": "9d5af3f1-6658-4c4e-8fb2-1b06cb9c4bd1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "source": [
        "#The same similarity, and mostSimilar works with transpose as input.\n",
        "mostSimilar(movie_df, 'Just My Luck', 2)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['The Night Listener', 'Snakes on a Plane'], dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 122
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uovtHynnYR2Y",
        "colab_type": "text"
      },
      "source": [
        "### Given a movie, say B, could you write a function to recommend those peoples who have not seen this movies but they may rank this movie with high score? For example, who are those two persons who will rate \"Just My Luck\" high but they never seen this movie before? (10%)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7aM0sAd6YR2b",
        "colab_type": "text"
      },
      "source": [
        "#### Solutions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3EmeIpVZYR2e",
        "colab_type": "code",
        "outputId": "9711abe0-790f-4d4f-beed-bf6a2d5da160",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "source": [
        "def suggest2(df, movie, numSuggest=2):\n",
        "  pNotWatched = df.loc[movie]\n",
        "  pNotWatched = pNotWatched[pNotWatched.isnull()].index.values\n",
        "  \n",
        "  #We can use same prediction function.. as we still go by similarity of person \n",
        "  pred_rating = pd.Series(index = pNotWatched)\n",
        "  for person in pNotWatched:\n",
        "    pred_rating[person] = prediction(df.transpose(), person, movie)\n",
        "    \n",
        "  watchThese = pred_rating.sort_values(ascending = False).index.values\n",
        "  return watchThese[0:numSuggest]\n",
        "\n",
        "\n",
        "suggest2(movie_df, 'Just My Luck')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['Michael Phillips', 'Jack Matthews'], dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 138
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KzTQLF-IYR2q",
        "colab_type": "text"
      },
      "source": [
        "### (20%) Data Preparation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rOJ4wdJtYR2t",
        "colab_type": "text"
      },
      "source": [
        "### 1. Data quality can be assessed in terms of accuracy, completeness, and consistency. What other factors are also important to data quality (5%)? "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nuv-JzJ3YR2v",
        "colab_type": "text"
      },
      "source": [
        "#### Solutions\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y6aPqdSEZLn1",
        "colab_type": "text"
      },
      "source": [
        "- Accuracy : The degree to which data correctly describes the \"real world\" object or event\n",
        "being described.\n",
        "- Completeness : The proportion of stored data against the potential of “100%\n",
        "complete”\n",
        "- Consistency : The absence of difference, when comparing two or more representations of a\n",
        "thing against a definition\n",
        "- Uniqueness : Nothing will be recorded more than once based upon how that thing is\n",
        "identified. It is the inverse of an assessment of the level of duplication\n",
        "- Timeliness : The degree to which data represent reality from the required point in time\n",
        "- Validity : Data are valid if it conforms to the syntax (format, type, range) of its definition"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CVF8jM6yYR29",
        "colab_type": "text"
      },
      "source": [
        "### 2.  Suppose that the data for analysis includes the attribute age. The age values for the data tuples are (in increasing order) 13, 15, 16, 16, 19, 20, 20, 21, 22, 22, 25, 25, 25, 25, 30, 33, 33, 35, 35, 35, 35, 36, 40, 45, 46, 52, 70  (10%).\n",
        "\n",
        "(a) What is the mean of the data? What is the median?\n",
        "\n",
        "(b) What is the mode of the data? Comment on the data's modality (i.e., bimodal, trimodal, etc.).\n",
        "\n",
        "(c) What is the midrange of the data?\n",
        "\n",
        "(d) Can you find (roughly) the first quartile (Q1) and the third uartile (Q3) of the data? \n",
        "\n",
        "(e) Give the five-number summary, minimum, Q1, median, Q3, maximum, of the data.\n",
        "\n",
        "(f) Show a boxplot of the data from (e).\n",
        "\n",
        "(g) How is a quantile-quantile plot different from a quantile plot? (The quantile-quantile (q-q) plot is a graphical technique for determining if two data sets come from populations with a common distribution.  A q-q plot is a plot of the quantiles of the first data set against the quantiles of the second data set.)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rhCDROz2YR3B",
        "colab_type": "text"
      },
      "source": [
        "#### Solution\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZdGqhfr6YR3D",
        "colab_type": "code",
        "outputId": "8168654d-344e-4d94-811a-de7b53b64c2a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        }
      },
      "source": [
        "data = [13, 15, 16, 16, 19, 20, 20, 21, 22, 22, 25 ,25 ,25, 25, 30, 33, 33, 35, 35, 35, 35, 36, 40, 45, 46, 52, 70]\n",
        "data = pd.Series(data)\n",
        "print(\"Length of the data is {}\".format(len(data)))\n",
        "print(\"Mean is {}, Median is {}.\".format(data.mean(), data.median()))\n",
        "print(\"Modes are {}, modality is {}\".format(data.mode().values, len(data.mode().values)))\n",
        "#Bimodal in this testcase.\n",
        "print(\"Midrange is {}\".format((data.iloc[0] + data.iloc[-1])/2.0))\n",
        "print(\"First quartile Q1 is {}, third quartile Q3 is {}\".format(\n",
        "  data.quantile(.25, interpolation='nearest'), \n",
        "  data.quantile(.75, interpolation='nearest')))\n",
        "print(\"Summary of data: minimum={}, Q1={}, median={}, Q3={}, maximum={}\".format(\n",
        "  data.min(), \n",
        "  data.quantile(.25, interpolation='nearest'),\n",
        "  data.median(),\n",
        "  data.quantile(.75, interpolation='nearest'),\n",
        "  data.max()))\n",
        "\n",
        "#Note that this shows upper whisker till 52, and 70 is detected as outlier.\n",
        "print(\"Box plot showing the summary.\")\n",
        "data.plot.box()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Length of the data is 27\n",
            "Mean is 29.962962962962962, Median is 25.0.\n",
            "Modes are [25 35], modality is 2\n",
            "Midrange is 41.5\n",
            "First quartile Q1 is 20, third quartile Q3 is 35\n",
            "Summary of data: minimum=13, Q1=20, median=25.0, Q3=35, maximum=70\n",
            "Box plot showing the summary.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f9f0f83c1d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD8CAYAAABn919SAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Lv9c2gHYR3L",
        "colab_type": "text"
      },
      "source": [
        "### 3. In practical data, tuples with missing values for some attributes are a common occurrence. Describe various methods for handling this problem (5%) ."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hX2T95p6YR3N",
        "colab_type": "text"
      },
      "source": [
        "#### Solutions\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PHJhXWf2Xuqd",
        "colab_type": "text"
      },
      "source": [
        "- Ignore the tuple when class value is missing.\n",
        "- Manually fill in missing values.\n",
        "- Use global constant to replace missing values. Say NaN, -inf, etc.\n",
        "- Using mean of quantitative values. Mode for categorical values. \n",
        "- Using mean and mode for all samples belonging to same class as given tuple.\n",
        "- Fill using most probable value determined by regresion, inference , Bayesian, DT etc."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ly2_Ra5zYR3Z",
        "colab_type": "text"
      },
      "source": [
        "## (30%) How to Acquire & Refine the Data\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7EVarSAUYR3b",
        "colab_type": "text"
      },
      "source": [
        "## Items, Users, Signal\n",
        "\n",
        "- **Items**: Objects to be recommended\n",
        "- **Users**: Target of the recommendation\n",
        "- **Signal**: Explicit or Implicit feedback between Items and users\n",
        "\n",
        "In our context\n",
        "- Items are **stories** posted on HN\n",
        "- Users are **users** commenting or posting stories\n",
        "- Signal are **comments** on the stories by the user signalling interest"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3DZs5ObmYR3e",
        "colab_type": "text"
      },
      "source": [
        "## Source of Data \n",
        "\n",
        "Lets see the sources for getting historical information posted on HackerNews\n",
        "\n",
        "- **HackerNews API** - YCombinator provides an official hackernew api through Firebase. This is a near real-time database and provides both an *items* (stories and comments) as well as an *users* api.  It is available at https://github.com/HackerNews/API\n",
        "\n",
        "- **BigQuery** : Google Big Query has a daily updated HackerNews public dataset available (from 2006 to date). It only has *items* information. It is available at https://bigquery.cloud.google.com/table/bigquery-public-data:hacker_news.full"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DYpxLObEYR3k",
        "colab_type": "text"
      },
      "source": [
        "## Items (Stories) \n",
        "\n",
        "The schema for the Big Query table is\n",
        "\n",
        "| Field       | Type      | Description                           |\n",
        "|:------------|----------:|:--------------------------------------|\n",
        "| by          | STRING    | The username of the item's author.    |\n",
        "| score       | INTEGER   | Story score                           |\n",
        "| time        | INTEGER   | Unix time                             |\n",
        "| timestamp   | TIMESTAMP | Timestamp for the unix time           |\n",
        "| title       | STRING    | Story title                           |\n",
        "| type        | STRING    | Type of details (comment, story, ...) |\n",
        "| url         | STRING    | Story url                             |\n",
        "| text        | STRING    | Story or comment text                 |\n",
        "| parent      | INTEGER   | Parent comment ID                     |\n",
        "| deleted     | BOOLEAN   | Is deleted?                           |\n",
        "| dead        | BOOLEAN   | Is dead?                              |\n",
        "| descendants | INTEGER   | Number of story or poll descendants   |\n",
        "| id          | INTEGER   | The item's unique id.                 |\n",
        "| ranking     | INTEGER   | Comment ranking                       |\n",
        "\n",
        "\n",
        "- Get all the stories posted on HackerNews in **2017 (till date)**. \n",
        "- To ensure a relevant set, we will limit the stories which have atleast have **score of 5 points or more** on them. \n",
        "\n",
        "This dataset is available in `stories2017score5.gzip`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K-xAVFKgYR3m",
        "colab_type": "text"
      },
      "source": [
        "### Could you read file stories2017score5.csv.gzip by Python pandas package and plot histogram of scores(10%) "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5F1vs-6UYR3r",
        "colab_type": "text"
      },
      "source": [
        "#### Solutions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GSXX8IhVYR3u",
        "colab_type": "code",
        "outputId": "00a817a2-031e-4735-e304-059de9117263",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 318
        }
      },
      "source": [
        "stories = pd.read_csv('gdata/stories2017score5.csv.gzip', compression='gzip', header=0, sep=',', quotechar='\"')\n",
        "stories.hist(column='score', bins=20)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[<matplotlib.axes._subplots.AxesSubplot object at 0x7f7f2cd71ac8>]],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 143
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYcAAAEICAYAAAC0+DhzAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ndQwHSVLHcJAkdf4/L6k12Wxe+ewAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0svgUO9vYR31",
        "colab_type": "text"
      },
      "source": [
        "### Most Popular Stories (5%)\n",
        "\n",
        "For this exercise:\n",
        "- Let us choose the most popular stories with a score > 500 over the last year\n",
        "- Lets keep the columns - user (by), userId (id), score (score), title (title)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "komv149jYR33",
        "colab_type": "text"
      },
      "source": [
        "#### Solutions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eZAHfh39YR37",
        "colab_type": "code",
        "outputId": "309cc8ac-339e-48ff-b8e3-3d9573e07c1a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        }
      },
      "source": [
        "top500 = stories[stories['score']>500]\n",
        "top500 = top500[['by', 'id', 'score', 'title']]\n",
        "top500.head()\n",
        "top500.sample(5)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>by</th>\n",
              "      <th>id</th>\n",
              "      <th>score</th>\n",
              "      <th>title</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>52252</th>\n",
              "      <td>davidcornu</td>\n",
              "      <td>15368104</td>\n",
              "      <td>633</td>\n",
              "      <td>Draggable JS – a lightweight, responsive, mode...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33176</th>\n",
              "      <td>v3ss0n</td>\n",
              "      <td>13421608</td>\n",
              "      <td>948</td>\n",
              "      <td>RethinkDB Postmortem</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27051</th>\n",
              "      <td>mathgenius</td>\n",
              "      <td>14338411</td>\n",
              "      <td>620</td>\n",
              "      <td>Why do many math books have so much detail and...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40469</th>\n",
              "      <td>vladikoff</td>\n",
              "      <td>15800676</td>\n",
              "      <td>3001</td>\n",
              "      <td>macOS High Sierra: Anyone can login as “root” ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>53100</th>\n",
              "      <td>ingve</td>\n",
              "      <td>15270189</td>\n",
              "      <td>527</td>\n",
              "      <td>Discover the world of microcontrollers through...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "               by  ...                                              title\n",
              "52252  davidcornu  ...  Draggable JS – a lightweight, responsive, mode...\n",
              "33176      v3ss0n  ...                               RethinkDB Postmortem\n",
              "27051  mathgenius  ...  Why do many math books have so much detail and...\n",
              "40469   vladikoff  ...  macOS High Sierra: Anyone can login as “root” ...\n",
              "53100       ingve  ...  Discover the world of microcontrollers through...\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 144
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bPgKrSE9YR4F",
        "colab_type": "text"
      },
      "source": [
        "###  Item (Story) - User - Signal (Comment) Lets get all the comments from the database by reviewing fifle (bycomments2017score5.csv.gz) and keep only the user and story information. Please see what problems in data and dealing with them. Show me processed data shapes (how many rows and column) and first five rows of  processed data (5%).\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9wN-sWvNYR4H",
        "colab_type": "text"
      },
      "source": [
        "#### Solutions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6MMOq7FXYR4K",
        "colab_type": "code",
        "outputId": "2f5ebe0f-371a-4c1d-fef4-b4fb5ce1bc98",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 243
        }
      },
      "source": [
        "comments = pd.read_csv('gdata/bycomments2017score5.csv.gz', compression='gzip', header=0, sep=',', quotechar='\"')\n",
        "comments.dropna(inplace = True)\n",
        "print(\"Shape of the data is: {}\".format(comments.shape))\n",
        "print(\"First 5 rows are below\")\n",
        "comments.head()\n",
        "\n",
        "#Parent is the story ID. It can be used as below.\n",
        "#stories[stories['id'] == comments.iloc[0]['parent']]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape of the data is: (436347, 2)\n",
            "First 5 rows are below\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>by</th>\n",
              "      <th>parent</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>13153</th>\n",
              "      <td>05</td>\n",
              "      <td>15878548</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13154</th>\n",
              "      <td>0a</td>\n",
              "      <td>13850516</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13155</th>\n",
              "      <td>1k</td>\n",
              "      <td>15783427</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13156</th>\n",
              "      <td>1k</td>\n",
              "      <td>14602595</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13157</th>\n",
              "      <td>21</td>\n",
              "      <td>14192353</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       by    parent\n",
              "13153  05  15878548\n",
              "13154  0a  13850516\n",
              "13155  1k  15783427\n",
              "13156  1k  14602595\n",
              "13157  21  14192353"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 150
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LamRMzYaYR4T",
        "colab_type": "text"
      },
      "source": [
        "### Users information (10%). \n",
        "\n",
        "We need to get the details for all the users that have made comments in our list of stories.\n",
        "\n",
        "Also, we are interested in their details\n",
        "- How long have they been on the HN platform? (Created)\n",
        "- How active they are? (# of comments)?\n",
        "- How good they are to the HN community (karma)?\n",
        "\n",
        "We will need to get the User Information from HN\n",
        "\n",
        "- **Hacker News API**: Official API hosted on Firebase - https://github.com/HackerNews/API\n",
        "- **Haxor**: Unofficial HN Python API c- https://github.com/avinassh/haxor\n",
        "- **Ascynio-HN**: A very fast async Python API for HackerNews - https://github.com/itielshwartz/asyncio-hn\n",
        "\n",
        "### Think how you use API to get all uses data information. Download them and save them. Will be used later."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SPZGlWzSYR4W",
        "colab_type": "text"
      },
      "source": [
        "#### Solutions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zwrc6r_OYR4Y",
        "colab_type": "code",
        "outputId": "175ae66d-19ec-4322-de4c-cd4aaf95674d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 56
        }
      },
      "source": [
        "from firebase import firebase\n",
        "firebase = firebase.FirebaseApplication('https://hacker-news.firebaseio.com/v0/', None)\n",
        "result = firebase.get('user/', '05')\n",
        "print(result)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'created': 1433941859, 'id': '05', 'karma': 272, 'submitted': [20210674, 20202827, 20094158, 20088297, 19938169, 19699372, 19655308, 19638903, 19638845, 19628591, 19485954, 19464424, 19458482, 19440819, 19355122, 19342832, 19330149, 19310030, 19309012, 19262359, 19262122, 19247523, 19243861, 19243321, 19242209, 19184896, 19172939, 18996837, 18963696, 18963585, 18813684, 18812975, 18812887, 18795261, 18765627, 18740906, 18691405, 18611002, 18437833, 18115978, 17973604, 17925146, 17890909, 17719810, 17615533, 17536369, 17493469, 17492823, 17142203, 16963001, 16948294, 16874824, 16874795, 16869259, 16792469, 16742473, 16733225, 16710387, 16686605, 16661158, 16661085, 16661044, 16660658, 16636705, 16537266, 16400417, 16292110, 16292049, 16260139, 16240033, 16190159, 16146330, 16039883, 16039786, 15880963, 15719844, 15637491, 15624527, 15574294, 15571306, 15016247, 14709934, 14664665, 14646227, 14523814, 14218075, 13474239, 13257369, 13230926, 13029854, 12085215, 11975751, 11952300, 11887358, 11812729, 11795531, 11691952, 11616201, 11610525, 11607963, 11607684, 11604286, 11603574, 11588994, 11588312, 11583475, 11566700, 11566635, 11560674, 11558347, 11552988, 11542864, 11542413, 11542339, 11541070, 11459762, 11422804, 11405477, 11401447, 11359954, 11359383, 11249924, 11249897, 11224793, 11223903, 11194290, 11186735, 11177505, 11164420, 11154536, 11154489, 11148739, 11138479, 11132112, 11128014, 11127946, 11127852, 11097241, 10912107, 10911950, 10898794, 10766149, 10735176, 10731604, 10730518, 10643604, 10562526, 10235817]}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0VrftLiNVK54",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "users = pd.DataFrame(columns=['user', 'created', 'numComments', 'karma'])\n",
        "\n",
        "#This takes ~4 hours to run. Generates hw1_users.csv.gz file.\n",
        "\n",
        "#for user in comments['by'].unique():\n",
        "#  result = firebase.get('user/', user)\n",
        "#  created = result.get('created', 0)\n",
        "#  numComments = len(result.get('submitted', []))\n",
        "#  karma = result.get('karma', 0)\n",
        "  \n",
        "#  users = users.append({'user': user, \n",
        "#                        'created': created, \n",
        "#                        'numComments': numComments,\n",
        "#                        'karma': karma}, ignore_index=True)\n",
        "\n",
        "#users.to_csv('gdata/hw1_users.csv.gz', compression='gzip')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sftg7VVVZPvv",
        "colab_type": "code",
        "outputId": "87f37a20-552b-451a-da79-3fc993661b17",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        }
      },
      "source": [
        "#loading pre-saved data of above cell.\n",
        "commentsHN = pd.read_csv('gdata/hw1_users.csv.gz', compression='gzip', header=0, sep=',', quotechar='\"')\n",
        "commentsHN.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>user</th>\n",
              "      <th>created</th>\n",
              "      <th>numComments</th>\n",
              "      <th>karma</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>05</td>\n",
              "      <td>1433941859</td>\n",
              "      <td>148</td>\n",
              "      <td>272</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>0a</td>\n",
              "      <td>1477215580</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>1k</td>\n",
              "      <td>1494221943</td>\n",
              "      <td>30</td>\n",
              "      <td>53</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>21</td>\n",
              "      <td>1454365382</td>\n",
              "      <td>1705</td>\n",
              "      <td>5141</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>2m</td>\n",
              "      <td>1416411507</td>\n",
              "      <td>3</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0 user     created  numComments  karma\n",
              "0           0   05  1433941859          148    272\n",
              "1           1   0a  1477215580            1      3\n",
              "2           2   1k  1494221943           30     53\n",
              "3           3   21  1454365382         1705   5141\n",
              "4           4   2m  1416411507            3      9"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 149
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X5Zj451BYR4h",
        "colab_type": "text"
      },
      "source": [
        "## (30%) Feature Engineering (Data Transform)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ga7MU4OPYR4i",
        "colab_type": "text"
      },
      "source": [
        "How do we create the user-item matrix for the HackerNews Dataset\n",
        "- OneHot Encoding\n",
        "- Sparse Matrix (for scalability)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9DjcZU95YR4n",
        "colab_type": "text"
      },
      "source": [
        "### What is OneHot Encoding and its purpose (5%). Could you apply OneHot to encode previous obtained story user comment data from bycomments2017score5.csv.gz ? Show encoded data previous few rows. (10%)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lIODteFSYR4q",
        "colab_type": "text"
      },
      "source": [
        "#### Solutions:\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rs52-3fCOgvD",
        "colab_type": "text"
      },
      "source": [
        "A one hot encoding is a representation of categorical variables as binary vectors.\n",
        "\n",
        "This first requires that the categorical values be mapped to integer values.\n",
        "\n",
        "Then, each integer value is represented as a binary vector that is all zero values except the index of the integer, which is marked with a 1."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y6ZbI3ueYR4t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Try on first 1000 else it exceed RAM usage.\n",
        "comments = comments.head(1000) \n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "# binary encode\n",
        "user_encoder = OneHotEncoder(sparse=False)\n",
        "user_encoded = user_encoder.fit_transform(comments['by'].values.reshape(-1, 1))\n",
        "comment_encoder = OneHotEncoder(sparse=False, categories='auto')\n",
        "comment_encoded = comment_encoder.fit_transform(comments['parent'].values.reshape(-1, 1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "McdLCtP2StxZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Copy dataframe and replace by with one-hot-encoded value.\n",
        "#Here I have applied one-hot encoding to both user(by) and commentId(parent)..\n",
        "comments_enc = comments.head(1000).copy(deep=True)\n",
        "comments_enc['parent'] = comments_enc['parent'].astype(object)\n",
        "iter = 0\n",
        "for i, row in comments_enc.iterrows():\n",
        "  comments_enc.at[i,'by'] = user_encoded[iter]\n",
        "  #comments_enc.at[i,'parent'] = comment_encoded[iter]\n",
        "  iter = iter + 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LZsTZUUwX5D6",
        "colab_type": "code",
        "outputId": "a0b0fb29-5887-4a89-abc8-6817a8114e4f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        }
      },
      "source": [
        "comments_enc.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>by</th>\n",
              "      <th>parent</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>13153</th>\n",
              "      <td>[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
              "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13154</th>\n",
              "      <td>[0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
              "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13155</th>\n",
              "      <td>[0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
              "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13156</th>\n",
              "      <td>[0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
              "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13157</th>\n",
              "      <td>[0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
              "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                      by                                             parent\n",
              "13153  [1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...\n",
              "13154  [0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...\n",
              "13155  [0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...\n",
              "13156  [0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...\n",
              "13157  [0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 153
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NERZB3DSYR40",
        "colab_type": "text"
      },
      "source": [
        "### Could you what is Coordinate list (COO) compression format for sparse matrix generation (5%)\n",
        "### Implment this to compress previous obtained story user comment data from bycomments2017score5.csv.gz (10%)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lHkzt5ouYR42",
        "colab_type": "text"
      },
      "source": [
        "#### Solutions\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vtY0nCShuE0B",
        "colab_type": "text"
      },
      "source": [
        "Sparse matrix is an efficient way to store matrix with lots of zero values, and relatively low number of NNZ (non-zero) values. It stores only non-zero value (all 1 in our case for one-hot encoding), and pointer to each non-zero value. \n",
        "CSR (Compressed sparse row),  CSC(Compressed sparse column), COO(Coordinate list) are different formats of sparse representation. \n",
        "\n",
        "Matrix operations like addition, multiplication, etc can be done directly on sparse representation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y6r6SnRJYR44",
        "colab_type": "code",
        "outputId": "2a0e7871-c85b-4de9-9e9e-76fb8f9da2e5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "from scipy.sparse import coo_matrix\n",
        "user_coo = coo_matrix(user_encoded)\n",
        "comment_coo = coo_matrix(comment_encoded)\n",
        "\n",
        "#The user is in sparse format now.\n",
        "user_coo"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<1000x86 sparse matrix of type '<class 'numpy.float64'>'\n",
              "\twith 1000 stored elements in COOrdinate format>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 154
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lXx6XMzWz0lX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Copy dataframe and replace by with one-hot-encoded value.\n",
        "#comments_coo = comments_enc.copy(deep=True)\n",
        "#iter = 0\n",
        "#for i, row in comments_enc.iterrows():\n",
        "#  comments_coo.at[i,'by'] = user_coo[iter]\n",
        "#  comments_coo.at[i,'parent'] = comment_coo[iter]\n",
        "#  iter = iter + 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iNLQ_ONez11I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}